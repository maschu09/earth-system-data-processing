# ERA5 HEALPix Regridding Pipeline

**Author:** Patrick Seidel  
**Course:** Earth System Data Processing, WS 2025/26  
**Assignment:** Homework \#2  
**Disclaimer:** For the sake of readability and aesthetics, this readme and the documentation in the code was partly generated by [claude.ai](https://www.claude.ai). The core idea and code were created by me without any outside help.

---

## Project Overview

This project implements an automated pipeline for downloading ERA5 atmospheric reanalysis data from the Copernicus Climate Data Store, regridding it from standard lat-lon grids to HEALPix format at multiple resolutions, and storing the results efficiently in Zarr format.

---

## Development Notes & Reflections

### Technical Challenges & Solutions

**API Client Selection**  
The new `ecmwf-datastores-client` is in incubation phase with potential breaking changes. Used the stable `cdsapi` library instead.

**HEALPix Interpolation**  
Implemented area-weighted averaging where all lat-lon points falling within each HEALPix pixel are averaged. Used NumPy's `bincount` for efficient aggregation.

**Zarr Append Corruption**  
Encountered NaN values in all but the most recent timesteps after appending. Root cause: concatenating lazy dask arrays from Zarr with eager numpy arrays, then deleting the source before lazy evaluation completed. Fixed by forcing `.load()` when opening existing Zarr stores.

**Zarr Format Compatibility**  
Initial saves used Zarr v3, causing `AttributeError` on load due to xarray incompatibility. Fixed by specifying `zarr_format=2`.

### Chunking Strategy

Initially set chunks to 20 timesteps (5 days), but increased to **48 timesteps** (~12 days) for better scalability:
- Keeps chunks in optimal 1-10 MB range
- Balances spatial queries with time-series efficiency
- Supports multi-year datasets without excessive chunk proliferation

---

## Repository Structure
```
earth-system-data-processing/
└── data_access/
    ├── README_era5-healpix-pipeline.md  # This file
    ├── requirements.txt                 # Python dependencies
    ├── era5_healpix_pipeline.py         # Main pipeline orchestration
    ├── era5_downloader.py               # ERA5 data download via CDS API
    ├── healpix_converter.py             # Lat-lon to HEALPix conversion
    ├── zarr_utils.py                    # Zarr I/O utilities
    ├── create_plots.ipynb               # Visualization notebook
    └── downloads/era5/
        ├── netcdf/                      # NetCDF files
        └── healpix/                     # Output HEALPix Zarr stores
````

---

## Installation & Setup

### Prerequisites

- Python 3.8 or higher
- CDS API account (free registration required)

### Step 1: Clone Repository
```bash
git https://github.com/PaSeidel/earth-system-data-processing 
cd earth-system-data-processing/data_access
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Configure CDS API Credentials

1. Register at https://cds.climate.copernicus.eu/
2. Accept the terms of use for the ERA5 dataset
3. Get your API credentials from your account settings
4. Create `~/.cdsapirc` with the following content:
```
url: https://cds.climate.copernicus.eu/api
key: <your-uid>:<your-api-key>
```

---

## Usage

### Quick Start

Process ERA5 data for a date range (downloads, regrids, and saves to Zarr):
```python
from datetime import date
from era5_healpix_pipeline import ERA5HealpixPipeline

# Initialize pipeline
pipeline = ERA5HealpixPipeline(
    data_dir="./downloads/era5/",
    single_zarr_file=True,    # Consolidate all days in single Zarr files
    redownload=False,          # Skip already-downloaded files
    debug=False                # Set True to test without downloading
)

# Process data for December 1-5, 2024
pipeline.process_and_archive_daily_data(
    start_date=date(2024, 12, 1),
    end_date=date(2024, 12, 5)
)
```

### Command-Line Execution

Run the main script directly:
```bash
python era5_healpix_pipeline.py
```

This executes the pipeline with default settings (December 1-5, 2024).

### Date Specification Options

The pipeline supports flexible date ranges:
```python
# Option 1: Fixed single date
pipeline.process_and_archive_daily_data(fixed_date=date(2024, 12, 1))

# Option 2: Date range
pipeline.process_and_archive_daily_data(
    start_date=date(2024, 12, 1),
    end_date=date(2024, 12, 31)
)

# Option 3: Start date to present (minus 5 days)
pipeline.process_and_archive_daily_data(start_date=date(2024, 12, 1))

# Option 4: From beginning of ERA5 archive
pipeline.process_and_archive_daily_data(end_date=date(2024, 12, 31))
```

**Note**: ERA5 data is available from January 1, 1940 until 5 days before the current date.

### Custom Download Configuration

Specify custom variables, pressure levels, times, and spatial extent:
```python
from datetime import date
from era5_downloader import ERA5Downloader

# Define custom configuration
custom_config = {
    "variable": ["temperature", "geopotential"],
    "pressure_level": ["500", "850", "1000"],
    "time": ["00:00", "12:00"],
    "area": [60, -20, 30, 40]  # [North, West, South, East] in degrees
}

# Initialize downloader
downloader = ERA5Downloader(data_dir="./downloads/era5/netcdf/", config=custom_config)

# Download with custom config
downloader.download_data_for_date(
    date(2024, 12, 1)
)
```

**Available configuration options:**
- `variables`: List of ERA5 variable names (e.g., "temperature", "u_component_of_wind")
- `pressure_levels`: List of pressure levels as strings (e.g., "500", "850", "1000")
- `times`: List of hours as strings (e.g., "00:00", "06:00", "12:00", "18:00")
- `area`: Bounding box as [North, West, South, East] in degrees

### Configuration Parameters
```python
ERA5HealpixPipeline(
    data_dir="./downloads/era5/",   # Base directory for all data
    single_zarr_file=True,           # True: one Zarr per resolution
                                     # False: separate Zarr per day
    redownload=False,                # True: re-download existing files
    debug=False                      # True: skip downloads, test logic only
)
```

### Loading Processed Data
```python
import xarray as xr

# Load HEALPix datasets
ds_hp8 = xr.open_zarr("./downloads/era5/healpix/era5_healpix_nside8_consolidated.zarr")
ds_hp16 = xr.open_zarr("./downloads/era5/healpix/era5_healpix_nside16_consolidated.zarr")

# Inspect structure
print(ds_hp8)
print(f"Time range: {ds_hp8.time.values[0]} to {ds_hp8.time.values[-1]}")
print(f"Variables: {list(ds_hp8.data_vars)}")

# Access specific variable
specific_humidity = ds_hp8['q']  # kg/kg
relative_humidity = ds_hp8['r']  # %

# Load data into memory (required for plotting)
ds_hp8_loaded = ds_hp8.load()
```

---

## Data Format & Structure

### Input Data (ERA5)

- **Source**: Copernicus Climate Data Store
- **Variables**: Specific humidity (q), Relative humidity (r)
- **Pressure levels**: 975, 900, 800, 500, 300 hPa
- **Temporal resolution**: 6-hourly (00:00, 06:00, 12:00, 18:00 UTC)
- **Spatial resolution**: 0.25° × 0.25° (native ERA5)
- **Format**: NetCDF4

### Output Data (HEALPix Zarr)

**Dimensions:**
- `time`: Datetime64 timestamps (6-hourly intervals)
- `level`: Pressure levels in hPa (5 levels)
- `pixel`: HEALPix pixel indices (768 for NSIDE=8, 3,072 for NSIDE=16)

**Variables:**
- `q`: Specific humidity (kg/kg)
- `r`: Relative humidity (%)

**Attributes:**
- `healpix_nside`: Resolution parameter (8 or 16)
- `healpix_order`: Pixel ordering scheme (RING)
- `source`: Data provenance

**File Locations:**
- NSIDE=8: `./downloads/era5/healpix/era5_healpix_nside8_consolidated.zarr/`
- NSIDE=16: `./downloads/era5/healpix/era5_healpix_nside16_consolidated.zarr/`

### Zarr Chunking Strategy

The dataset is chunked as follows:

- **time**: 48 timesteps per chunk (~12 days of 6-hourly data)
- **level**: 1 pressure level per chunk (independent vertical access)
- **pixel**: all pixels per chunk (complete spatial coverage)

This results in chunks of approximately 295 KB (NSIDE=8) and 1.18 MB (NSIDE=16) per variable, well within the optimal 1-10 MB range.

**Storage layout:**
- For 5 days (20 timesteps): 5 chunks total (1 per pressure level)
- For 100 days (400 timesteps): 45 chunks (9 time chunks × 5 levels)

The chunking prioritizes:
1. Complete spatial coverage for mapping at individual pressure levels
2. Efficient time series access with ~12-day segments
3. Scalability for multi-year datasets

---

## Visualization

See `create_plots.ipynb` for examples of:
- Comparing original lat-lon grids with regridded HEALPix data
- Side-by-side visualization of NSIDE=8 vs NSIDE=16 resolutions

---

## Technical Details

### HEALPix Interpolation Method

The pipeline uses an **area-weighted averaging** approach:
1. For each HEALPix pixel, identify all lat-lon grid points that fall within it
2. Average the values of these grid points
3. Assign the average to the HEALPix pixel

This method is conservative (preserves global means) and appropriate for humidity variables.

### Debug Mode

Test pipeline logic without downloading:
```python
pipeline = ERA5HealpixPipeline(debug=True)
pipeline.process_and_archive_daily_data(
    start_date=date(2024, 12, 1),
    end_date=date(2024, 12, 5)
)
```

Output shows which dates get downloaded without API calls or file I/O.

---

## License

This project is part of academic coursework. Please cite appropriately if used.