{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Homework 1",
   "id": "e433eb49627be0ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "To access the sentinel1 data via the openEO api the corresponding python client package is required. It can be installed from pip by running `pip install openeo` in a terminal with python installed. If you'd like to modify this script for your own needs see the documentation of the openEO Python Client at https://openeo.org/documentation/1.0/python/#full-example."
   ],
   "id": "391cfa765298b7e9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-03T14:56:17.045069Z",
     "start_time": "2025-12-03T14:56:17.039671Z"
    }
   },
   "source": [
    "import openeo\n",
    "import math\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Authentication\n",
    "When executing the Cell bellow a link will be printed to the console. Follow this link to authenticate with your login."
   ],
   "id": "b397c66d23a19ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T14:56:18.187621Z",
     "start_time": "2025-12-03T14:56:17.052725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "connection = openeo.connect(\"openeofed.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ],
   "id": "5f6f491ad5b8837a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Connection to 'https://openeofed.dataspace.copernicus.eu/openeo/1.2/' with OidcBearerAuth>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sanity Check\n",
    "To check weather the connection is alive, we request all available data collections and filter for collections linked to Sentinel 1."
   ],
   "id": "4ed626382be96c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T14:56:18.367759Z",
     "start_time": "2025-12-03T14:56:18.219244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c_ids = filter(lambda x: x.startswith(\"SENTINEL1\"), connection.list_collection_ids()) #filter connection list for any item that starts with \"SENTINEL1\"\n",
    "for c_id in c_ids: #unfortunatly needed to print out filtering results\n",
    "    print(c_id)"
   ],
   "id": "ee0f151cef534006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTINEL1_GRD\n",
      "SENTINEL1_GLOBAL_MOSAICS\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Config\n",
    "In the following Cell we define the temporal and spatial extent of our area of interest and the stride at which the area of interest is sliced into chunks. Additional month can be added to the list and the download will work with no problem. Changing the interval that will be averaged later would require code changes."
   ],
   "id": "aa9fbabf4f3462fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:06:00.573273Z",
     "start_time": "2025-12-03T15:06:00.570535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "long_start = 3.5\n",
    "long_end = 8.5\n",
    "long_stride = 1\n",
    "\n",
    "lat_start = 51.5\n",
    "lat_end = 55.5\n",
    "lat_stride = 1\n",
    "\n",
    "months=['2024-05']"
   ],
   "id": "1a26e036eabe6262",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Cell bellow calculates the coordinates for the chunks.",
   "id": "82a399689eb86d43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T14:56:18.390426Z",
     "start_time": "2025-12-03T14:56:18.387314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "long_steps = [long_start + i * long_stride for i in range(math.ceil((long_end - long_start) / long_stride))]\n",
    "lat_steps = [lat_start + i * lat_stride for i in range(math.ceil((lat_end - lat_start) / lat_stride))]\n",
    "\n",
    "long_steps"
   ],
   "id": "11256970482de2fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 4.5, 5.5, 6.5, 7.5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The function defined bellow is used to automatically retry a given lambda up to n times if an error occurs during execution. This is used to make sure the download doesn't get interrupted by a network failure. However, it could be utilized for any operation that has a failure probability which cannot be easily mitigated.",
   "id": "dcb35c408fe532d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T14:56:18.397546Z",
     "start_time": "2025-12-03T14:56:18.395177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def n_trys(n, function):\n",
    "    for i in range(n): # try n times\n",
    "        try:\n",
    "            function() # execute lambda\n",
    "            return\n",
    "        except KeyboardInterrupt: # explicitly handle KeyboardInterrupt, otherwise we wouldn't be able to stop the execution conveniently\n",
    "            raise KeyboardInterrupt\n",
    "        except: # notify the user but retry for any other exception\n",
    "            print(f\"an exception occurred in try {i}\")\n",
    "    raise ConnectionError(f\"Download function couldn't be completed successfully in {n} trys\") # raise an exception if all n trys fail"
   ],
   "id": "9d8580f61060b2cf",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Main Loop\n",
    "The following cell contains the main logic for downloading the data."
   ],
   "id": "f6305cec4327a403"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-03T15:08:17.742609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for month in months:\n",
    "    for lat_step_start in lat_steps: #iterate over latitude steps\n",
    "        lat_step_end = lat_step_start + lat_stride\n",
    "        for long_step_start in long_steps: #iterate over longitude steps\n",
    "            long_step_end = long_step_start + long_stride\n",
    "\n",
    "            #this dict defines the current chunk\n",
    "            bbox = {\"west\": long_step_start, \"south\": lat_step_start, \"east\": long_step_end, \"north\": lat_step_end}\n",
    "            print(f\"downloading {bbox}\", end=\" \") #some output for the user\n",
    "\n",
    "            datacube = connection.load_collection( # config for the download\n",
    "                \"SENTINEL1_GRD\",\n",
    "                temporal_extent = month,\n",
    "                spatial_extent = bbox,\n",
    "                bands = [\"VV\",\"VH\"],\n",
    "            )\n",
    "\n",
    "            data_slice = datacube.reduce_temporal(\"mean\") # form the average over one month to get a stable and complete image\n",
    "\n",
    "            # this data slug will be used to store the data\n",
    "            file_slug = f\"../data/sentinel1_grd/{month}/{lat_step_start}-{lat_step_end}/{long_step_start}-{long_step_end}/\"\n",
    "\n",
    "            # the following if blocks check whether a file has already been created and skips those. That means if you change something you either need to delete old data or define the slug / file postfix differently\n",
    "            if not os.path.exists(file_slug + \"vv.tif\"):\n",
    "                n_trys(5, lambda: data_slice.band(\"VV\").download(file_slug + \"vv.tif\")) # stores the VV polarisation band\n",
    "            print(\"vv\", end=\" \")\n",
    "\n",
    "            if not os.path.exists(file_slug + \"vh.tif\"):\n",
    "                n_trys(5, lambda: data_slice.band(\"VH\").download(file_slug + \"vh.tif\")) # stores the VH polarisation band\n",
    "            print(\"vh\", end=\" \")\n",
    "\n",
    "            if not os.path.exists(file_slug + \"vv&vh.tif\"):\n",
    "                combined_band = data_slice.reduce_bands(\"mean\") # combines both bands by forming the average\n",
    "                n_trys(5, lambda: combined_band.download(file_slug + \"vv&vh.tif\")) #stores both bands\n",
    "            print(\"vv&vh\")"
   ],
   "id": "a6bba0e6d2d25c71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading {'west': 3.5, 'south': 51.5, 'east': 4.5, 'north': 52.5} vv vh vv&vh\n",
      "downloading {'west': 4.5, 'south': 51.5, 'east': 5.5, 'north': 52.5} vv vh vv&vh\n",
      "downloading {'west': 5.5, 'south': 51.5, 'east': 6.5, 'north': 52.5} vv "
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
